# -*- mode: ruby -*-
# # vi: set ft=ruby :

require 'fileutils'
require 'erb'

Vagrant.require_version ">= 1.8.0"

CONFIG = File.join(File.dirname(__FILE__), "vagrant/config.rb")

COREOS_URL_TEMPLATE = "https://storage.googleapis.com/%s.release.core-os.net/amd64-usr/current/coreos_production_vagrant.json"

SUPPORTED_OS = {
#  "coreos-stable" => {box: "coreos-stable",      bootstrap_os: "coreos", user: "core", box_url: COREOS_URL_TEMPLATE % ["stable"]},
#  "coreos-alpha"  => {box: "coreos-alpha",       bootstrap_os: "coreos", user: "core", box_url: COREOS_URL_TEMPLATE % ["alpha"]},
#  "coreos-beta"   => {box: "coreos-beta",        bootstrap_os: "coreos", user: "core", box_url: COREOS_URL_TEMPLATE % ["beta"]},
"ubuntu" => {box: "bento/ubuntu-16.04", bootstrap_os: "ubuntu", user: "vagrant"},
#  "centos"        => {box: "bento/centos-7.3",   bootstrap_os: "centos", user: "vagrant"},
}

$instance_name_prefix = "ubuntu"

class HostClass
  attr_reader :name, :domain, :ip_offset, :vm_prefix, :subnet, :ip

  def initialize(idx, vm_prefix, subnet, ip_offset)
    @name = "%s-%d" % [vm_prefix, idx]
    @domain = ".interubernet.local"
    @vm_prefix = vm_prefix
    @subnet = subnet
    @ip_offset = ip_offset
    @ip = subnet+"."+ip_offset
  end

  def display_details()
    puts "Name: #@name"
    puts "Domain: #@domain"
    puts "VM prefix: #@vm_prefix"
    puts "Network: #@subnet"
    puts "IP offset: #@ip_offset"
    puts "IP: #@ip"
  end
end

def get_hosts()
  hosts = []

  (1..3).each do |i|
    hosts.push(HostClass.new(i, "ubuntu", "10.20.30", "#{i+70}"))
  end
  (4..5).each do |i|
    hosts.push(HostClass.new(i, "ubuntu", "192.168.50", "#{i+70}"))
  end
  hosts
end

# hosts = get_hosts
#
# hosts[1..-1].each do |x|
#   x.display_details()
#   #print x.ip + "\n"
#   print "\n"
# end


def get_hosts_file_template()
  %{# This file is generated by the Vagrantfile and is overwritten when machine is provisioned

# The following lines are desirable for IPv4 capable hosts
127.0.0.1       localhost

# 127.0.1.1 is often used for the FQDN of the machine
127.0.0.1 <%= @current_host.name %><%= @current_host.domain %> vagrant.vm vagrant
<% for @host in @all_hosts %><%=
@host.ip %> <%= @host.name %><%= @host.domain %> <%= @host.name %>
<% end %>

# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

}
end

class HostFileRenderer
  include ERB::Util
  attr_accessor :items, :template

  def initialize(current_host, all_hosts, template)
    @current_host = current_host
    @all_hosts = all_hosts
    @template = template
  end

  def render()
    ERB.new(@template).result(binding)
  end

  def save(file)
    File.open(file, "w+") do |f|
      f.write(render)
    end
  end

end


get_hosts[0..-1].each do |host|
  list = HostFileRenderer.new(host, get_hosts, get_hosts_file_template)
  list.save(File.join(host.name+'.hosts'))
end

# Defaults for config options defined in CONFIG
#$num_instances = machines.length

$vm_gui = false
$vm_memory = 1536
$vm_cpus = 1
$shared_folders = {}
$forwarded_ports = {}
$os = "ubuntu"
# The first three nodes are etcd servers
#$etcd_instances = get_hosts.length
# The first two nodes are masters
#$kube_master_instances = $num_instances == 1 ? $num_instances : ($num_instances - 1)
#$kube_master_instances = 1
$local_release_dir = "/vagrant/temp"


host_vars = {}

if File.exist?(CONFIG)
  require CONFIG
end

# All nodes are kube nodes
#$kube_node_instances = get_hosts.length

$box = SUPPORTED_OS[$os][:box]
# if $inventory is not set, try to use example
#$inventory = File.join(File.dirname(__FILE__), "inventory") if ! $inventory
#print $inventory + "\n"

# if $inventory has a hosts file use it, otherwise copy over vars etc
# to where vagrant expects dynamic inventory to be.
#if ! File.exist?(File.join(File.dirname($inventory), "hosts"))
#  $vagrant_ansible = File.join(File.dirname(__FILE__), ".vagrant", "provisioners", "ansible")
#  print $vagrant_ansible + "\n"
#  FileUtils.mkdir_p($vagrant_ansible) if ! File.exist?($vagrant_ansible)
#  print File.join($vagrant_ansible,"inventory") + "\n"

#  if ! File.exist?(File.join($vagrant_ansible,"inventory"))
#    FileUtils.ln_s($inventory, $vagrant_ansible)
#  end
#end

#if Vagrant.has_pxlugin?("vagrant-proxyconf")
#  $no_proxy = ENV['NO_PROXY'] || ENV['no_proxy'] || "127.0.0.1,localhost"
#  machines.each do |machine|
#    #print ",#{$machine.ip}\n"
#    $no_proxy += ",#{$machine.ip}"
#  end
#end

Vagrant.configure("2") do |config|
  # always use Vagrants insecure key - If true, Vagrant will automatically insert a keypair to use for SSH, replacing Vagrant's default insecure key inside the machine if detected. By default, this is true.
  config.ssh.insert_key = false
  config.vm.box = $box
  if SUPPORTED_OS[$os].has_key? :box_url
    config.vm.box_url = SUPPORTED_OS[$os][:box_url]
  end
  config.ssh.username = SUPPORTED_OS[$os][:user]
  # plugin conflict
  if Vagrant.has_plugin?("vagrant-vbguest") then
    config.vbguest.auto_update = false
  end

  get_hosts.reverse.each do |machine|
    config.vm.define vm_name = machine.name do |config|
      config.vm.hostname = vm_name

#      if Vagrant.has_plugin?("vagrant-proxyconf")
#        config.proxy.http = ENV['HTTP_PROXY'] || ENV['http_proxy'] || ""
#        config.proxy.https = ENV['HTTPS_PROXY'] || ENV['https_proxy'] || ""
#        config.proxy.no_proxy = $no_proxy
#      end

      if $expose_docker_tcp
        config.vm.network "forwarded_port", guest: 2375, host: ($expose_docker_tcp + i - 1), auto_correct: true
      end

      $forwarded_ports.each do |guest, host|
        config.vm.network "forwarded_port", guest: guest, host: host, auto_correct: true
      end

      ["vmware_fusion", "vmware_workstation"].each do |vmware|
        config.vm.provider vmware do |v|
          v.vmx['memsize'] = $vm_memory
          v.vmx['numvcpus'] = $vm_cpus
        end
      end

      $shared_folders.each do |src, dst|
        config.vm.synced_folder src, dst
      end

      config.vm.provider :virtualbox do |vb|
        vb.gui = $vm_gui
        vb.memory = $vm_memory
        vb.cpus = $vm_cpus
      end

      ip = machine.ip
      host_vars[vm_name] = {
          "ip": ip,
          #"flannel_interface": ip,
          "flannel_interface": "enp0s8",
          "flannel_backend_type": "host-gw",
          #"flannel_backend_type": "vxlan",
          "local_release_dir" => $local_release_dir,
          "download_run_once": "False",
          # Override the default 'calico' with flannel.
          # inventory/group_vars/k8s-cluster.yml
          "kube_network_plugin": "flannel",
          "bootstrap_os": SUPPORTED_OS[$os][:bootstrap_os]
      }
      # assign a static ip to the NIC
      config.vm.network :private_network, ip: ip

      # uncomment to upgrade to latest packages
#      config.vm.provision "shell", inline: "apt-get -y update"
#      config.vm.provision "shell", inline: "apt-get -y upgrade"

      #config.vm.provision "file", "/vagrant/"+source: machine.name+".hosts", destination: "/etc/hosts"
      config.vm.provision "shell", inline: "cp /vagrant/"+machine.name+".hosts /etc/hosts"

      if "ubuntu-01" == machine.name then
        config.vm.provision "file", source: "~/.vagrant.d/insecure_private_key", destination: ".ssh/id_rsa"


        # add all the other hosts execept ubuntu-01 to ~/.ssh/known-hosts
        get_hosts[1..-1].each do |machine|
            config.vm.provision "shell", privileged: false, inline: "ssh -o StrictHostKeyChecking=no "+machine.name+" exit"
        end

        # sudo mkdir -p /etc/ansible/roles/kubernetes
        # sudo ln -s -T /vagrant/ /etc/ansible/roles/kubernetes

        config.vm.provision "shell", inline: "sudo apt-get -y install bash-completion ansible sshpass apt-transport-https ca-certificates curl software-properties-common python-pip "
        #config.vm.provision "shell", inline: "cp /vagrant/dnsmasq.conf /etc/dnsmasq.conf"
        #config.vm.provision "shell", inline: "systemctl restart dnsmasq.service"
        config.vm.provision "shell", inline: "pip install netaddr"
        #config.vm.provision "shell", inline: "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -"
        #config.vm.provision "shell", inline: 'sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"'
        #config.vm.provision "shell", inline: "sudo apt-get -y update"
        #config.vm.provision "shell", inline: "sudo apt-get -y install docker-ce"

#        config.vm.provision :ansible_local do |ansible|
#            ansible.playbook = 'tasks/main.yaml'
#            #ansible.inventory_path = 'hosts'
#            ansible.host_vars = {
#                      "ubuntu-01" => {"http_port" => 80,
#                              "maxRequestsPerChild" => 808},
#                  "ubuntu-02" => {"http_port" => 303,
#                              "maxRequestsPerChild" => 909}
#                }
#            ansible.limit = 'all'
#            ansible.verbose        = true
#            ansible.install        = true
#        end
#

      else
          $conf = <<EOF
cat > /etc/resolv.conf <<EOF2
    nameserver 10.20.30.71
    search webspeed.dk
EOF2
EOF
            #resolv.conf and hosts
            config.vm.provision "shell", inline: $conf, run: "always"
      end



# Only execute once the Ansible provisioner,
# when all the machines are up and ready.
#      if i == $num_instances
#        config.vm.provision "ansible" do |ansible|
#          ansible.playbook = "cluster.yml"
#          if File.exist?(File.join(File.dirname($inventory), "hosts"))
#            ansible.inventory_path = $inventory
#          end
#          ansible.sudo = true
#          ansible.limit = "all"
#          ansible.host_key_checking = false
#          ansible.raw_arguments = ["--forks=#{$num_instances}"]
#          ansible.host_vars = host_vars
#          #ansible.tags = ['download']
#          ansible.groups = {
#            "etcd" => ["#{$instance_name_prefix}-0[1:#{$etcd_instances}]"],
#            "kube-master" => ["#{$instance_name_prefix}-0[1:#{$kube_master_instances}]"],
#            "kube-node" => ["#{$instance_name_prefix}-0[1:#{$kube_node_instances}]"],
#            "k8s-cluster:children" => ["kube-master", "kube-node"],
#          }
#        end
#      end

      end
    end
  end
